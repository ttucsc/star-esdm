classdef ARRM_V2_RunParams
    %ARRM_V2 run parameter container and parsing code.
%   Constructor creates, and update(...) modifies a RunParams object for use in ARRM_V2 programs
%
%   Both the constructor and update(...) take matlab name, value pairs to set any of the RunParams.
%
%       data members can be set directly, but using the parser will error-check the values, and in some cases update
%       related parameters.
%   
%       Use variable name in quotes, followed by desired value, as keyword/value pair.
%       Where value requires multiple values, provide vector of values.
%       Explanations and default values are given below.
%       Terms may be in any order;  any term not specified uses the defaults given below.
%       (varargin may also be a vararginStruct from matlab's parse(...) function.)
%
%               Examples:
%           'clim_nterms', 8, 'clim_sig_terms', 1, 'yrlen', 360, ...
%
%       varargin Keywords       Description
%       _________________       ___________
%           edges         Defines edges (bottom values) specification to use for histogramming to create the pdfs.
%                                   Given as either [minval, stepsize, maxval], as in [-50,.1,50]; or vector of edges.
%                                   Setting this sets both edges and bins for use in histogramming
%
%                               Default values for these are set to reasonable values for processing temperature data.
%           weights             weights to use to merge multiple data series.  1 weight per data series
%                                   if missing, will assume even weighting for all sets.  (These should be moved to DataParams, Ian!)
%                                   usually the weights generated by bilinear interpolation from nearest gridpoints.
%           pdf_yrstep          # of years between each moving pdf.  integer. [10]
%                                   change this if you expect the pdf to change significantly at time scales faster than 10 years.
%                                            0:   create single pdf from all input data
%                                           >0:  create multiple pdf's, using pdf_yrs years in each pdf, and stepping
%                                                forward by pdf_yrstep 
%           pdf_yrs             # of years of data for each pdf. [31]  Should be odd (will add 1 if not)
%                                           Note: if pdf_yrstep ~= 0 && # years of data <= pdf_yrs, then 
%                                                 a single pdf is created from the data
%          Climatology Filter Parameters
% OBSOLETE          do_normalize_sigmas         (was used to normalize at a different point in the process.)
%               sigma_normalize         boolean.  If true, normalizes anomalies so they all have approximately the same
%                                           std_dev.  This keeps the size of the histograms to a reasonable size.
%                                           Otherwise, if the summer distributions are widely different from winter
%                                           distributions, the system can run out of memory.
%                                               Appropriate for temperature distributions, but not precip.
%               median_normalize        boolean.  If true, centers precip distributions to have a common median.
%                                               Appropriate for precip, but not for temperature distributions.
%               clim_nterms             # of terms to keep (for 1 year of data).  6 is a good value to use for temperature. [6]
%               clim_sig_terms          # of terms to use for gaussian to convolve w/ nterms to create filter.  [2]
%                                       nterms=6 and sigterms=6 are good to use for temperature.
%                                       sigterms=0 creates an ideal lowpass filter.  But this usually produces somewhat
%                                       periodic residuals, driven by 1st frequency passed by filter.
%                                       2 is good value to use
%               anom_nterms             same as above, but used for calculating the climatology of the anomalies
%               anom_sig_terms          [2,4]  &  [1,2] are good for anom climatology.
%                                           These can be 2-elements long;  first is used to smooth surface
%                                               second is used to calculate std_devs of anomalies for sigma_normalize
%  OBSOLETE         sigrange            # of days to use for day-smoothing the climatology and kde-smoothed histogram surface 
%                                   (14 is good)  [14]  Currently not used.
%           nclim_yrs           equivalent # of years to use for smoothing the climatology surface along the years. [31]
%           n_ext_yrs           min # of years to extend the data by (needed to avoid wrapping effect of FFT) [30]
%                                   should be at least 2x nclim_yrs.
%                                   code will increase this so FFT is working with next power of 2 for efficiency.
%           trend_order         Trend order for removing long-term trend  ['calc']
%                                   NA: do not detrend
%                                   'calc': calculate the trend based on the number of years of valid data.
%                                       0 : just remove mean
%                                       >0: remove 1st, 2nd, 3rd, order trend etc. from data
%                                       1  is good for 20-40 yrs data;  3 is a good value for > 50 yrs data
%                                       NOTE:  use 0 (remove mean) or 1 (remove linear trend) for short periods, or NA to skip detrending
%                                       NOTE:  string 'calc' : calculate the trend order
%                                               in which case it passes in a value between 0 & 3, based on amount of valid data.
%           trend_yr_flags      'calc', or vector of boolean flags, one for each year of data, identifying which years
%                                           to use for detrending (years with limited # of valid data points should 
%                                           be excluded to avoid biasing the results.)
%                                       true:  use this year in the detrending calculation
%                                       false:  leave this year out of detrending calculation.
%                                       Set to empty (or all true) to use all data for detrending.
%                                       Set to string 'calc' to calculate.  Years with less than trend_thresh valid data 
%                                       will be excluded (trend_yr_flag(i) set to false) 
%           trend_thresh                fraction of valid data in a given yr below which to exclude from trend calculation [.8]
%           cdf_thresh                  minimum threshold for pdf/cdf calculations.  1e-6 is good for temperature data, 1e-3 for precip. 
%           outlier_thresh              probability inside of which to do CDF mapping for downscaling.
%           far_outlier_thresh          Assumption is that inside this threshold, the PDFs are reasonably accurate,
%                                       but outside this point, anomalies are non-gaussian & not predictable.
%           far_outlier_anchor_pt       Used for alternate mapping calculation for far outliers.                                               
%                                       Outside this point, ARRM V2 uses an empirical CDF from a large range of locations
%                                           To use it, it normalizes the outliers by using this value.
%                                           I.e., it scales by the ratio of the far_outlier_anchor_pt points for 
%                                           obs and model.  If 2 values given, mapping is done out to 2nd value, but
%                                           ratio used is ratio at 1st value.  E.g., [1e-3, 1e-4] maps points out to
%                                           1e-4;  points outside that are mapped to ratio of 1e-3 points.
%                                           1e-3 or 1e-4 is reasonable for temperature.
%                                   
%                                       1e-3  is +/- ~3 sigma   prob of normally distributed temp anomalies outside this 
%                                                                   is approx. 1 every 3 years
%                                       1e-4  is +/- ~-3.7 sigma, approx. 1 every 30 years. 
%                                       3e-5  is +/- ~4 sigma   1 every 85 years
%                                       3-e7  is +/- ~5 sigma   1 in 10,000 years
%                                       1e-9  is +/- ~6 sigma
%                                       1e-12 is +/- ~7 sigma
%                                       Default is 1e-3.  
%                                           Below ~1e-12, normal linear mapping won't work because surface
%                                           is flat (not monotonically increasing) in the tails.  
%                                           ARRM_V2 calculates probabilities out to 7 sigma (1e-12).
%           'probs', probs              vector of probabilities to calculate probability lines for
%                                           default:  [.001,.01,.025,.05,.10,.1587,.50,.8413,.90,.95,.975, .99, .999];
%                                                                ^              ^         ^            ^
%                                                                |            +/- 1 std. dev           |
%                                                           ~ -2 st devs                          ~ +2 st devs
        
            % data years
%
%---
%
%   12/2021 icsf  changed constructor so upstream code must pass in a varname, so we know whether to set up
%                         default params for temperature runs or precip runs.
%                         added set_default_params based on  varname
%                               currently sets pdf_map_method and *_nterms and *_sig_terms if empty.
%                               Setting default params could be smarter...
%---

    properties
        yrlen           = 365;              % length of year for data (data should be adjusted to this yrlen if not the 
                                            % year length in the raw data read from files.
        do_fixNAs       = true;

            % trend variables
        trend_yr_flags  = 'calc';
        trend_thresh    = .8;
        trend_order     = 'calc';
        
            % pdf/cdf variables
        pdf_yrstep      = 10;
        pdf_yrs         = 31;
        cdf_thresh      = 1e-6;             % bounds for "extreme_outliers"  (i.e., bad data)
        adjust_pdfs     = true;
        outlier_thresh        = 1e-3;       % for identifying "outliers".   Use .0228 (2-sigma) for precip.
        far_outlier_thresh    = 1e-4;       % for identifying far-outliers. Use .01 for precip. 
        far_outlier_anchor_pt = 1e-3;       % for scaling outliers.         Use .0228 (2 sigma) for precip.
        na_thresh       = 1e-8;             % threshold beyond which to map to NA

        pdf_yrlen       = 128;              % remap day-of-year to 128 days
        pdf_map_method  = strings(0);       % 'cos(clim)':  use cosine(slope(annual climatology) to remap time
                                            % 'linear':     use linear time mapping.    S/B default for temp runs
                                            % "clim":       use climatology (of # of wet days), s/b default for precip
                                            % "wetclim":    abs(cos(slope(clim)))*wet_day_climatology   experimental.  needs to be tested for precip 
                                            % 
        
        sigma_normalize = [];               % should to be turned on for temperature runs, off for precip runs.  Must be explicitly set.
        median_normalize = false;              % s/b off for temp, on for precip. (???) Also must be explicitly set.
        
%         sigrange_probs  = [.001,.1,.9,.999]; % ranges for variable gaussians (if length(sigrange) > 1).  4 values;  adjust between 1st 2, and adjst between 2nd 2.
%         sig_adj_linear = false;
        
        isPrecipRun = [];           % must be set to true or false in order to use correct defaults for pdf_map_method, *_nterms & *sig_terms
        prcp_distrib = strings(0);  % will set to default later when we know if we're doing a precip run or not.
            % filter parameters
        clim_nterms = [];
        clim_sig_terms = [];
        anom_nterms = [];
        anom_sig_terms = [];
                % defaults for temperature runs 
%         pdf_map_method = "linear";  
%         clim_nterms     = 6;
%         clim_sig_terms  = 2;
%         anom_nterms     = [2,4];    % use 4 to filter std. deviation for reshaping, use 2 for smoothing surface
%         anom_sig_terms  = [1,2];    % ditto above.
%         sigrange        = 14;       % add 2nd sigrange value for adjusting sigrange in the tails.
%                                     % NOTE:  sigrange not used currently.  It is used when filtering PDFs along the time
%                                     % dimension, which we don't do anymore.  (We map into z-space and smooth along
%                                     % z-score lines.)
%
                % defaults for precip runs
%         pdf_map_method = "clim";  
%         clim_nterms     = 5;
%         clim_sig_terms  = 2;
%         anom_nterms     = 2;    % use 2 to filter std. deviation for reshaping, use 2 for smoothing surface
%         anom_sig_terms  = 1;    % ditto above.
%
        nclim_yrs       = 31;
        n_ext_yrs       = 63;
                    
            % histogramming parameters
        
        edges      = [];    % edges in the original data space
        zedges    = [];    % edges in z-space.
        out_edges  = [];
            
            % miscellaneous
        weights         = 1;
        merge_seed      = 1;
%         probs           = [.00001, .0001,.001,.01,.0228,.05,.10,.1587,.50,.8413,.90,.95,.9772, .99, .999,.9999, .99999];
% %                                                   ^             ^         ^            ^
% %                                                   |           +/- 1 std. dev           |
% %                                          ~ -2 st devs (.0228)                 ~ +2 st devs (.9772)
        probs  = [0., .00001, .0001,.001, .00621, .01,.0228,.05,.10,.1587,.50,.8413,.90,.95,.9772, .99, .99379, .999,.9999, .99999, 1.0];
%                                     ^      ^           ^             ^         ^            ^            ^      ^
%                                     |      |           |           +/- 1 std. dev           |            |      |
%                                     |      |   ~ -2 st devs (.0228)               ~ +2 st devs (.9772)   |      |
%                                   -3.09  -2.5                                                          +2.5   +3.09

        
        runType         = 'unknown';
        
            % select which calculations get done.
        do_anomalies    = true;
        do_calc_binning = true;         % false makes it use default binning.  Will calculate binning if true or if edges is empty.
                                        % if true, will calc. minimum binning needed for run (max range + 7.5 silverman
                                        % sigmas)
                                        % NOTE:  will calc binning even if false, but will start from default edges,
                                        % which may be larger than needed.
        do_histograms   = true;
        do_pdfs         = true;        
        do_problines    = false;
        do_base_probs   = false;        % set to true to calculate probabilities for all base points
        do_rolling_probs= false;        % set to true to calculate probabilities for all rolling points
        do_daily_trends = false;        % calc daily long-term trend.  For locations merging multiple gridcells, 
                                        % Set to true only on last run, not on intermediate runs.
        
        Unmatched       = [];
        
            % list of parameters to exclude when saving to netcdf files.
        ncExcludeList     = {'do_anomalies','do_calc_binning','do_histograms','do_pdfs','do_problines','do_base_probs','do_rolling_probs','do_daily_trends','bins','Unmatched','ncExcludeList'};
    end
    properties(SetAccess = private)
        bins=[];
        binstep=0;
        out_bins = [];
        out_binstep = [];      % should be called out_binstep, Ian.
        zbins = [];
        zbinstep = [];
    end
        
    methods
        function obj = ARRM_V2_RunParams(varname, varargin)

                    % parse input for runType
%             p = inputParser;      % do this manually, because we don't want to remove runType from the list of args.
%             p.StructExpand = true;
%             p.KeepUnmatched = true;    
%             addParameter(p,'runType',obj.runType);
%             parse(p, varargin{:});
%             runType = p.Results.runType;
%             args = p.Unmatched;        % save rest of input params for later
            
            ix=[];
            for i=1:2:length(varargin); if (strcmpi('runType',varargin{i})), ix=i; end; end
            if (~isempty(ix))
                runType=string(varargin{ix+1});
%                 varargin(ix:ix+1) = [];         % don't want to remove this, because it is used in both RunParams and DataParams
            else
                runType="unknown"; 
            end
            obj = obj.set_default_params(varname);
            
                % apply standard parameters.
            if (exist('ARRM_V2_RunParams_TTUCSC.m','file'))
                obj = update(obj,ARRM_V2_RunParams_TTUCSC(runType));
                if (~isempty(fieldnames(obj.Unmatched))), error("unexpected parameters in ARRM_V2_RunParams_TTUCSC"); end
            end
                % apply any localized parameters if the function ARRM_V2_RunParams_localized( ) exists.
            if (exist('ARRM_V2_RunParams_localized.m','file'))
                obj = update(obj,ARRM_V2_RunParams_localized(runType));
                if (~isempty(fieldnames(obj.Unmatched))), error("unexpected parameters in ARRM_V2_RunParams_localized"); end
            end
            
%                 % now, check for an RP in the varagins
%                 % This applies any RP arguments before we run update(...) on the remaining args, so we can override
%                 % any RP arguments.
%             obj = obj.parse_for_RP(args); 
                        
                % now apply any command-line params (which are now in Unmatched);
%             obj = update(obj, args,'runType',runType);
            obj = update(obj, varargin{:});
        
        end
        
        function obj = update(obj, varargin)
            
            % Updates RunParams object.  Uses current values as defaults, and parses any key/value pairs
            % Call this when you want to set multiple parameters with a single function call.
            % To update a single parameter, just set the parameter directly.
    
            % I need to add verification to these still, Ian!

%                     % first, check for a RP in the varargins.
%             obj = obj.parse_for_RP(varargin{:});
%             args = obj.Unmatched;
            
            p = inputParser;
            p.StructExpand = true;
            p.KeepUnmatched = true;
            
            addParameter(p,'do_fixNAs',obj.do_fixNAs);
            addParameter(p,'yrlen', obj.yrlen);
            
            addParameter(p,'trend_yr_flags',obj.trend_yr_flags);
            addParameter(p,'trend_thresh',obj.trend_thresh);
            addParameter(p,'trend_order',obj.trend_order);
                        
            addParameter(p,'pdf_yrstep', obj.pdf_yrstep);
            addParameter(p,'pdf_yrs', obj.pdf_yrs);
            addParameter(p,'cdf_thresh',obj.cdf_thresh);                    % probability value beyond which PDFs & CDFs are considered invalid.
            addParameter(p,'adjust_pdfs',obj.adjust_pdfs);
            addParameter(p,'outlier_thresh',obj.outlier_thresh);            % probability value for flagging outliers.
            addParameter(p,'far_outlier_thresh',obj.far_outlier_thresh);    % probability value for flagging far-outliers
            addParameter(p,'far_outlier_anchor_pt',obj.far_outlier_anchor_pt);      % used for scaling in far-outlier corrections
%           addParameter(p,'na_thresh',obj.na_thresh);
            addParameter(p,'pdf_yrlen',obj.pdf_yrlen);
            addParameter(p,'pdf_map_method',obj.pdf_map_method);
            
%           addParameter(p,'do_normalize_sigmas', obj.do_normalize_sigmas, @(s) islogical(s));
            addParameter(p,'sigma_normalize', obj.sigma_normalize,   @(s) islogical(s) || (isnumeric(s) && any(s==[0,1])));
            addParameter(p,'median_normalize', obj.median_normalize, @(s) islogical(s) || (isnumeric(s) && any(s==[0,1])));
            addParameter(p,'clim_nterms',obj.clim_nterms);
            addParameter(p,'clim_sig_terms',obj.clim_sig_terms);
            addParameter(p,'anom_nterms',obj.anom_nterms);
            addParameter(p,'anom_sig_terms',obj.anom_sig_terms);
%           addParameter(p,'sigrange',obj.sigrange);
            addParameter(p,'nclim_yrs',obj.nclim_yrs);
            addParameter(p,'n_ext_yrs',obj.n_ext_yrs);
           
            addParameter(p,'edges',obj.edges);
            
            addParameter(p,'prcp_distrib',obj.prcp_distrib);
            
            
            addParameter(p,'weights',obj.weights);
            addParameter(p,'merge_seed',obj.merge_seed);
            addParameter(p,'probs',obj.probs);
            
            addParameter(p,'runType',obj.runType);
%             addParameter(p,'Unmatched',[]);

            addParameter(p,'do_anomalies', obj.do_anomalies);
            addParameter(p,'do_calc_binning', obj.do_calc_binning);
            addParameter(p,'do_histograms', obj.do_histograms);       % why isn't this obj.do_histograms, ian?
            addParameter(p,'do_pdfs', obj.do_pdfs);
            addParameter(p,'do_problines',obj.do_problines)
            addParameter(p,'do_base_probs',obj.do_base_probs);
            addParameter(p,'do_rolling_probs',obj.do_rolling_probs);
            addParameter(p,'do_daily_trends',obj.do_daily_trends);
                        
%             parse(p, args);
            parse(p, varargin{:});

            f=fields(p.Results);
            for i=1:length(f)
                if (isprop(obj, f{i}))
                    res=p.Results.(f{i});
                        % convert anything passed in as cell array of chars to array of strings                    
                    if (iscell(res) && ischar(res{1}))
                        res=string(res);
                    end
                    obj.(f{i}) = res;
                end
            end
            
%             if (obj.probs(1)   ~= 0.0), obj.probs=[0,obj.probs]; end   % make sure probabilities start at 1.
%             if (obj.probs(end) ~= 1.0), obj.probs(end+1) = 1.0; end    % make sure probabilities go all the way to 1.
                        
            obj.pdf_yrstep = min(obj.pdf_yrstep, obj.pdf_yrs);      % make sure yrstep <= pdf_yrs, so all years are covered.
            
            obj.Unmatched = p.Unmatched;
        end
        
        function obj = set.edges(obj, eee)
                obj.edges = eee;
            obj = obj.update_bins();
        end   

        function obj = set.out_edges(obj, eee)
                obj.out_edges = eee;
            obj = obj.update_out_bins();
        end   

        function obj = set.zedges(obj, eee)

            obj.zedges = eee;
            obj = obj.update_zbins();
        end   

        function RP_struct = toStruct(obj)
            props = properties(obj);
            RP_struct = struct();
            for i=1:length(props)
                prop = props{i};
                RP_struct.(prop) = obj.(prop);
            end
        end
        
%               clim_nterms             # of terms to keep (for 1 year of data).  6 is a good value to use for temperature. [6]
%               clim_sig_terms          # of terms to use for gaussian to convolve w/ nterms to create filter.  [2]
%                                       nterms=6 and sigterms=6 are good to use for temperature.
%                                       sigterms=0 creates an ideal lowpass filter.  But this usually produces somewhat
%                                       periodic residuals, driven by 1st frequency passed by filter.
%                                       2 is good value to use
%               anom_nterms             same as above, but used for calculating the climatology of the anomalies
%               anom_sig_terms          [2,4]  &  [1,2] are good for anom climatology.
%                                           These can be 2-elements long;  first is used to smooth surface
%                                               second is used to warp surface if sigma_normalize is true
%                                           smooth surface. (then warp back)
%         pdf_map_method = "linear";  
%         clim_nterms     = 6;
%         clim_sig_terms  = 2;
%         anom_nterms     = [2,4];    % use 4 to filter std. deviation for reshaping, use 2 for smoothing surface
%         anom_sig_terms  = [1,2];    % ditto above.

        function obj = set_default_params(obj, varname)
            if (is_prcp_variable(varname))
                obj.isPrecipRun = true;
                obj.prcp_distrib = "pwr"; % "loglogistic"; % strings(0);
                obj.pdf_map_method = "clim";
                obj.clim_nterms = 5;
                obj.clim_sig_terms = 2;
                obj.anom_nterms = 2; 
                obj.anom_sig_terms = [1,2];
                obj.probs = [0.5000 0.8413 0.9000 0.9500 0.9772 0.9900 0.9938 0.9990 0.9999 1.0000 1];
                obj.trend_yr_flags = [];
                obj.trend_thresh = 0;
                obj.trend_order = [];
                obj.cdf_thresh = .0005;        %  cdf not valid beyond .001.  (Ian:  This should be based on the number of precip events... )
                obj.outlier_thresh = [0,.99];    % flagged as outliers beyond 99th percentile 
                obj.far_outlier_thresh = [0,.999];  % flag far outliers beyond 99.9th percentile  (accept all points on the low end)    
                obj.far_outlier_anchor_pt = normcdf(-1);  % and use 1-sigma point for rescaling outliers. (-1 here because code elsewhere sets up thresholds using [prob,.5,1-prob],
                                                        % and then uses thresh(3) for upper thresh.  old value:  .1 <-> 90th percentile point for rescaling far outliers.
                obj.na_thresh = 1e-12;
                obj.sigma_normalize = [];
                obj.median_normalize = false; % this param doesn't work right for precip, and sigma_normalize is better for temp, so default to false now.  icsf 7/24/23.
            else
                obj.isPrecipRun = false;
                obj.pdf_map_method = "linear";
                obj.prcp_distrib = strings(0);
                obj.clim_nterms = 6;
                obj.clim_sig_terms = 2;
                obj.anom_nterms = [2,4];
                obj.anom_sig_terms = [1,2];
            end
        end
    
    end
    
    methods(Access = private)
        function obj = update_bins(obj)
            if (length(obj.edges)>1)
                obj.bins = (obj.edges(1:end-1)+obj.edges(2:end))/2;            
%               obj.binstep = obj.bins(2)-obj.bins(1);
                d = diff(obj.bins);
                obj.binstep = mean(d);
            else
                obj.bins=[];
                obj.binstep = 0;
            end
        end        
        function obj = update_out_bins(obj)
            if (length(obj.out_edges)>1)
                obj.out_bins = (obj.out_edges(1:end-1)+obj.out_edges(2:end))/2;            
%               obj.binstep = obj.bins(2)-obj.bins(1);
                d = diff(obj.out_bins);
                obj.out_binstep = mean(d);
            else
                obj.out_bins=[];
                obj.out_binstep = 0;
            end
        end        
        function obj = update_zbins(obj)       % zedges, and hence z-bins, need to be evenly spaced, usually using linspace(...)
            if (length(obj.zedges)>1)
                zdiffs = diff(obj.zedges);
                obj.zbins = obj.zedges(1:end-1)+zdiffs/2;            
%               obj.binstep = obj.bins(2)-obj.bins(1);
                obj.zbinstep = mean(zdiffs);
            else
                obj.zbins=[];
                obj.zbinstep = 0;
            end
        end        
    end
    
%     methods(Access=private)
%         
%         function obj = parse_for_RP(obj, varargin)
%             p = inputParser;
%             p.StructExpand = true;
%             p.KeepUnmatched = true;    
%             addParameter(p,'RP',[]);
%             parse(p, varargin{:});
%             RP = p.Results.RP;
%             if (~isempty(RP) && ~isa(RP,'ARRM_V2_RunParams'))
%                 error("error:  RP parameter is not an ARRM_V2_RunParams object");
%             end
%                     % copy fields into self.
%             props = properties(RP);
%             for i=1:length(props)
%                 try
%                     obj.(props{i}) = RP.(props{i});     % in a try block so loop doesn't abort on dependent properties.
%                 catch
%                     oops();
%                 end
%             end
%             obj.Unmatched = p.Unmatched;        % save rest of input params for later
%         end
%     end
end

